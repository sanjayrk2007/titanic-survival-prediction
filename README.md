
# Titanic Survival Prediction â€“ Logistic Regression Baseline

## ğŸ“Œ Project Overview
This project focuses on predicting passenger survival on the Titanic using **Logistic Regression**.  
The objective is to build a **clear and interpretable baseline model** using sound feature engineering practices, rather than leaderboard optimization.

This notebook serves as a **reference baseline** before moving on to more advanced models such as Random Forests and Gradient Boosting.

---

## ğŸ“‚ Dataset
- Source: Kaggle â€“ *Titanic: Machine Learning from Disaster*
- Files used:
  - `train.csv`
  - `test.csv`

### Target Variable
- `Survived`  
  - `0` â†’ Did not survive  
  - `1` â†’ Survived

---

## ğŸ” Approach

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)
- Identified missing values in `Age`, `Fare`, and `Embarked`
- Observed strong survival dependency on:
  - Gender
  - Passenger class
  - Family structure
  - Passenger titles

---

### 2ï¸âƒ£ Feature Engineering

The following features were engineered to improve predictive performance:

#### ğŸ”¹ Title Extraction
- Extracted passenger titles from the `Name` column
- Grouped rare titles into a single `Rare` category
- Normalized equivalent titles (e.g., *Mlle â†’ Miss*)
- Encoded titles numerically

#### ğŸ”¹ Age Imputation
- Missing ages filled using **median age per title group**
- Preserves demographic and social structure

#### ğŸ”¹ Family-Based Features
- `FamilySize = SibSp + Parch + 1`
- `IsAlone` created to identify solo travelers

#### ğŸ”¹ Categorical Encoding
- `Sex` encoded as binary (`male = 0`, `female = 1`)
- `Embarked` encoded numerically

---

### 3ï¸âƒ£ Feature Set Used
